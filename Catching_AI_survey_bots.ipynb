{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 5968827,
          "sourceType": "datasetVersion",
          "datasetId": 3422393
        }
      ],
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "nelgiriyewithana_mcdonalds_store_reviews_path = kagglehub.dataset_download('nelgiriyewithana/mcdonalds-store-reviews')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "Na9IeuRkRfsJ"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Setup"
      ],
      "metadata": {
        "id": "DwGt9PtqRfsL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Main imports, run always ---\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "\n",
        "from kaggle_secrets import UserSecretsClient\n",
        "user_secrets = UserSecretsClient()\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-01T08:22:57.474153Z",
          "iopub.execute_input": "2025-08-01T08:22:57.475173Z",
          "iopub.status.idle": "2025-08-01T08:22:57.495407Z",
          "shell.execute_reply.started": "2025-08-01T08:22:57.475128Z",
          "shell.execute_reply": "2025-08-01T08:22:57.494214Z"
        },
        "id": "r_rGQVpHRfsM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare the data with real reviews"
      ],
      "metadata": {
        "id": "wdD_5GedRfsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Prepare the data ---\n",
        "df_full = pd.read_csv('/kaggle/input/mcdonalds-store-reviews/McDonald_s_Reviews.csv', encoding = 'latin-1')\n",
        "df_full['word_count'] = df_full['review'].fillna('').apply(lambda x: len(x.split()))\n",
        "df_full = df_full [['review', 'rating','word_count']]\n",
        "\n",
        "\"\"\"\n",
        "# --- Extract city and state ---\n",
        "tmp = df_full['store_address'].str.extract(\n",
        "    r',\\s*([A-Za-z\\s]+?),\\s*([A-Z]{2})(?:\\s+\\d{5}(?:-\\d{4})?)?(?:\\s*,.*)?$'\n",
        ")\n",
        "df_full['city'] = tmp[0].str.strip()\n",
        "df_full['state'] = tmp[1]\n",
        "\"\"\"\n",
        "\n",
        "df_full.dropna(inplace=True)\n",
        "\n",
        "df_full.info()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-31T21:37:24.772248Z",
          "iopub.execute_input": "2025-07-31T21:37:24.773067Z",
          "iopub.status.idle": "2025-07-31T21:37:25.261517Z",
          "shell.execute_reply.started": "2025-07-31T21:37:24.773036Z",
          "shell.execute_reply": "2025-07-31T21:37:25.260353Z"
        },
        "id": "zxrdktxVRfsN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df_full['word_count'].describe()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-31T21:37:28.804465Z",
          "iopub.execute_input": "2025-07-31T21:37:28.804848Z",
          "iopub.status.idle": "2025-07-31T21:37:28.827224Z",
          "shell.execute_reply.started": "2025-07-31T21:37:28.804818Z",
          "shell.execute_reply": "2025-07-31T21:37:28.825857Z"
        },
        "id": "_YtMPBwBRfsN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Exclude reviews under 15 and over 54 words ---\n",
        "df_interim = (\n",
        "    df_full\n",
        "    .query(\"15 <= word_count <= 54\")\n",
        "    .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "df_interim['word_count_bin'] = pd.cut(\n",
        "    df_interim['word_count'],\n",
        "    bins=[15, 25, 35, 45, 55],\n",
        "    right=False\n",
        ")\n",
        "\n",
        "# --- Extract min and max from the interval objects ---\n",
        "df_interim['word_count_min'] = df_interim['word_count_bin'].apply(lambda x: x.left).astype(int)\n",
        "df_interim['word_count_max'] = df_interim['word_count_bin'].apply(lambda x: x.right - 1).astype(int)\n",
        "df_interim['word_count_bin_str'] = df_interim['word_count_bin'].astype(str) # get string, otherwise Gretel does not accept\n",
        "df_interim = df_interim.drop(columns=['word_count_bin'])\n",
        "\n",
        "# --- Create train and test sets ---\n",
        "train_frames, test_frames = [], []\n",
        "\n",
        "for (wb, r), g in df_interim.groupby(['word_count_bin_str', 'rating']):\n",
        "    if len(g) < 35:\n",
        "        raise ValueError(f\"({wb}, {r}) has only {len(g)} rows\")\n",
        "\n",
        "    # 25 for train, 10 for test\n",
        "    g_shuffled = g.sample(frac=1, random_state=42)  # shuffle once\n",
        "    train_frames.append(g_shuffled.iloc[:25])\n",
        "    test_frames .append(g_shuffled.iloc[25:35])\n",
        "\n",
        "df_real_train = pd.concat(train_frames).reset_index(drop=True)\n",
        "df_real_test  = pd.concat(test_frames ).reset_index(drop=True)\n",
        "\n",
        "df_real_train.to_csv(\"df_train.csv\", index=False)\n",
        "df_real_test.to_csv(\"df_test.csv\", index=False)\n",
        "\n",
        "print(\"Train shape:\", df_real_train.shape)\n",
        "print(\"Test shape:\", df_real_test.shape)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-31T21:45:49.859355Z",
          "iopub.execute_input": "2025-07-31T21:45:49.860377Z",
          "iopub.status.idle": "2025-07-31T21:45:49.940752Z",
          "shell.execute_reply.started": "2025-07-31T21:45:49.860339Z",
          "shell.execute_reply": "2025-07-31T21:45:49.939736Z"
        },
        "id": "YSOeOVjYRfsN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df_real_train.info()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-31T21:45:57.932468Z",
          "iopub.execute_input": "2025-07-31T21:45:57.932861Z",
          "iopub.status.idle": "2025-07-31T21:45:57.948738Z",
          "shell.execute_reply.started": "2025-07-31T21:45:57.932833Z",
          "shell.execute_reply": "2025-07-31T21:45:57.947771Z"
        },
        "id": "sqtTE_LbRfsO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate synthetic responses with Gretel.AI (API call, key required)"
      ],
      "metadata": {
        "id": "3nzECjpJRfsO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gretel-client\n",
        "\n",
        "# Ignore error messages"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-31T21:37:41.080361Z",
          "iopub.execute_input": "2025-07-31T21:37:41.081257Z",
          "iopub.status.idle": "2025-07-31T21:37:49.740568Z",
          "shell.execute_reply.started": "2025-07-31T21:37:41.081209Z",
          "shell.execute_reply": "2025-07-31T21:37:49.738518Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "OIYXicY-RfsO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from gretel_client.navigator_client import Gretel\n",
        "from gretel_client.data_designer import columns as C\n",
        "from gretel_client.data_designer import params as P\n",
        "from gretel_client.data_designer.params import GenerationParameters, ModelConfig\n",
        "\n",
        "gretel_api_key = user_secrets.get_secret(\"gretel_api_key\")\n",
        "gretel = Gretel(api_key=gretel_api_key)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-31T21:42:31.059476Z",
          "iopub.execute_input": "2025-07-31T21:42:31.059907Z",
          "iopub.status.idle": "2025-07-31T21:42:32.518532Z",
          "shell.execute_reply.started": "2025-07-31T21:42:31.05987Z",
          "shell.execute_reply": "2025-07-31T21:42:32.517376Z"
        },
        "id": "7puJqLp_RfsO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Sampler columns for the review topic and style ---\n",
        "def add_common_columns(designer):\n",
        "    designer.add_column(\n",
        "        C.SamplerColumn(\n",
        "            name=\"topic\",\n",
        "            type=P.SamplerType.CATEGORY,\n",
        "            params=P.CategorySamplerParams(values=[\"service speed\",\"food quality\",\"order accuracy\", \"cleanliness\",\"staff attitude\",\"convenience\"])\n",
        "        )\n",
        "    )\n",
        "    designer.add_column(\n",
        "        C.SamplerColumn(\n",
        "            name=\"style\",\n",
        "            type=P.SamplerType.CATEGORY,\n",
        "            params=P.CategorySamplerParams(values=[\"direct\",\"storytelling\",\"descriptive\", \"comparative\",\"evaluative\"])\n",
        "        )\n",
        "    )\n",
        "\n",
        "# --- Wrapper for synthetic data designer ---\n",
        "def generate_bucketed(df_seed, prefix: str):\n",
        "    \"\"\"\n",
        "    Generate synthetic reviews for every bucket in df_seed.\n",
        "    prefix is used for alias names so train/test runs do not clash.\n",
        "    Returns the concatenated synthetic frame.\n",
        "    \"\"\"\n",
        "    df_synth = df_seed.drop(columns='review')   # drop real review\n",
        "    synthetic_frames = []\n",
        "\n",
        "    for bin_str, (tok_min, tok_max) in bucket_map.items():\n",
        "        df_bin = df_synth[df_synth['word_count_bin_str'] == bin_str]\n",
        "        if df_bin.empty:\n",
        "            continue\n",
        "\n",
        "        alias = f\"{prefix}_{bin_str.replace('-', '_')}\"\n",
        "\n",
        "        prompt_tpl = (\n",
        "            \"Write a {{ rating }} review of a fast-food restaurant.\\n\"\n",
        "            \"- Length: {{ word_count_min }}–{{ word_count_max }} words.\\n\"\n",
        "            \"- Focus on: {{ topic }}\\n\"\n",
        "            \"- Style: {{ style }}\\n\"\n",
        "            \"- Do NOT mention the city, state, or restaurant name.\\n\"\n",
        "            \"Review:\"\n",
        "        )\n",
        "\n",
        "        cfg = ModelConfig(\n",
        "            alias=alias,\n",
        "            model_name=\"bedrock/meta-llama/Llama-3.1-70B-Instruct\",\n",
        "            generation_parameters=GenerationParameters(temperature=0.9, max_tokens=tok_max, top_p=0.90)\n",
        "        )\n",
        "\n",
        "        designer = (\n",
        "            gretel.data_designer\n",
        "                   .new(model_suite=\"llama-3.x\", model_configs=[cfg])\n",
        "                   .with_seed_dataset(df_bin)\n",
        "        )\n",
        "\n",
        "        add_common_columns(designer)\n",
        "\n",
        "        designer.add_column(\n",
        "            C.LLMTextColumn(\n",
        "                name=\"review\",\n",
        "                output_type=\"text\",\n",
        "                model_alias=alias,\n",
        "                prompt=prompt_tpl,\n",
        "                system_prompt=\"You recently visited a McDonald's restaurant.\"\n",
        "            )\n",
        "        )\n",
        "\n",
        "        run = designer.create(num_records=len(df_bin), wait_until_done=True)\n",
        "        synthetic_frames.append(run.dataset.df)\n",
        "\n",
        "    return pd.concat(synthetic_frames, ignore_index=True)\n",
        "\n",
        "bucket_map = {\n",
        "    \"[15, 25)\": (20, 35),\n",
        "    \"[25, 35)\": (33, 48),\n",
        "    \"[35, 45)\": (46, 62),\n",
        "    \"[45, 55)\": (59, 75)\n",
        "}"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-31T21:42:38.25779Z",
          "iopub.execute_input": "2025-07-31T21:42:38.258189Z",
          "iopub.status.idle": "2025-07-31T21:42:38.271922Z",
          "shell.execute_reply.started": "2025-07-31T21:42:38.258162Z",
          "shell.execute_reply": "2025-07-31T21:42:38.270926Z"
        },
        "id": "CxUqotRmRfsO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- run for train & test ---\n",
        "df_synth_train = generate_bucketed(df_real_train, prefix=\"train\")\n",
        "df_synth_test  = generate_bucketed(df_real_test,  prefix=\"test\")\n",
        "\n",
        "# --- add source labels ---\n",
        "df_real_train['source'] = 'real'\n",
        "df_real_test['source']  = 'real'\n",
        "df_synth_train['source'] = 'synthetic'\n",
        "df_synth_test['source']  = 'synthetic'\n",
        "\n",
        "# --- final merged sets ---\n",
        "df_train = pd.concat([df_real_train, df_synth_train], ignore_index=True)\n",
        "df_test  = pd.concat([df_real_test , df_synth_test ], ignore_index=True)\n",
        "\n",
        "# --- recompute word counts ---\n",
        "for df in (df_train, df_test):\n",
        "    df['word_count'] = df['review'].fillna('').str.split().str.len()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-31T21:46:02.824973Z",
          "iopub.execute_input": "2025-07-31T21:46:02.825368Z",
          "iopub.status.idle": "2025-07-31T22:27:52.156225Z",
          "shell.execute_reply.started": "2025-07-31T21:46:02.825342Z",
          "shell.execute_reply": "2025-07-31T22:27:52.15505Z"
        },
        "id": "bLDJxSuERfsP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Save for later\n",
        "df_train.to_csv(\"df_train.csv\", index=False)\n",
        "df_test.to_csv(\"df_test.csv\", index=False)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-31T22:30:58.935303Z",
          "iopub.execute_input": "2025-07-31T22:30:58.935701Z",
          "iopub.status.idle": "2025-07-31T22:30:58.962404Z",
          "shell.execute_reply.started": "2025-07-31T22:30:58.935676Z",
          "shell.execute_reply": "2025-07-31T22:30:58.961294Z"
        },
        "id": "GmSeLdVQRfsP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reviews length distributions"
      ],
      "metadata": {
        "id": "r15oZqS8RfsP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: re-load the data to reproduce the plots\n",
        "df_train = pd.read_csv(\"df_train.csv\")\n",
        "df_test = pd.read_csv(\"df_test.csv\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "i74KRiWERfsP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plt.style.use('default')\n",
        "fig, axes = plt.subplots(1, 2, figsize=(18, 4))\n",
        "\n",
        "sns.histplot(df_train['word_count'][df_train['source'] == 'real'], kde=True, bins=39, ax=axes[0], linewidth=1)\n",
        "axes[0].set_title('Distribution of Word Count | human reviews | train', loc='left', fontfamily='monospace')\n",
        "\n",
        "sns.histplot(df_train['word_count'][df_train['source'] == 'synthetic'], kde=True, bins=39, ax=axes[1], linewidth=1)\n",
        "axes[1].set_title('Distribution of Word Count | synthetic reviews | train', loc='left', fontfamily='monospace')\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "fig.axes[0].figure.savefig('human_reviews_wordcount_train_data.png')\n",
        "fig.axes[1].figure.savefig('synthetic_reviews_wordcount_train_data.png')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-31T22:39:58.535083Z",
          "iopub.execute_input": "2025-07-31T22:39:58.535507Z",
          "iopub.status.idle": "2025-07-31T22:39:59.556863Z",
          "shell.execute_reply.started": "2025-07-31T22:39:58.535482Z",
          "shell.execute_reply": "2025-07-31T22:39:59.555387Z"
        },
        "id": "2YCyUZTPRfsP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plt.style.use('default')\n",
        "fig, axes = plt.subplots(1, 2, figsize=(18, 4))\n",
        "\n",
        "sns.histplot(df_test['word_count'][df_test['source'] == 'real'], kde=True, bins=39, ax=axes[0], linewidth=1)\n",
        "axes[0].set_title('Distribution of Word Count | human reviews | test', loc='left', fontfamily='monospace')\n",
        "\n",
        "sns.histplot(df_test['word_count'][df_test['source'] == 'synthetic'], kde=True, bins=39, ax=axes[1], linewidth=1)\n",
        "axes[1].set_title('Distribution of Word Count | synthetic reviews | test', loc='left', fontfamily='monospace')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-31T22:37:12.87405Z",
          "iopub.execute_input": "2025-07-31T22:37:12.875078Z",
          "iopub.status.idle": "2025-07-31T22:37:13.516799Z",
          "shell.execute_reply.started": "2025-07-31T22:37:12.875038Z",
          "shell.execute_reply": "2025-07-31T22:37:13.515906Z"
        },
        "id": "JL5ugV1bRfsP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Analysis"
      ],
      "metadata": {
        "id": "O7S1fgeURfsP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sliding-window coherence"
      ],
      "metadata": {
        "id": "nmVURUZvRfsP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Optional: re-load the data ---\n",
        "df_train = pd.read_csv(\"df_train.csv\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "S1KC6NDURfsP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Make separate dataframe for analysis ---\n",
        "df_analysis = df_train[['review','rating','source','word_count','word_count_bin_str']]\n",
        "df_analysis.info()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-31T23:01:26.294502Z",
          "iopub.execute_input": "2025-07-31T23:01:26.29496Z",
          "iopub.status.idle": "2025-07-31T23:01:26.312036Z",
          "shell.execute_reply.started": "2025-07-31T23:01:26.294901Z",
          "shell.execute_reply": "2025-07-31T23:01:26.310808Z"
        },
        "id": "Zz8U1R4MRfsQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Ignore errors"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-31T22:41:53.309612Z",
          "iopub.execute_input": "2025-07-31T22:41:53.310739Z",
          "iopub.status.idle": "2025-07-31T22:42:02.59561Z",
          "shell.execute_reply.started": "2025-07-31T22:41:53.310699Z",
          "shell.execute_reply": "2025-07-31T22:42:02.59479Z"
        },
        "id": "ynk46nJARfsQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Sliding window functions ---\n",
        "def create_sliding_windows(tokens, window_size=3, step=1):\n",
        "    windows = []\n",
        "    for i in range(0, len(tokens) - window_size + 1, step):\n",
        "        windows.append(tokens[i:i + window_size])\n",
        "    return windows\n",
        "\n",
        "def compute_coherence_scores(embeddings):\n",
        "    if len(embeddings) < 2:\n",
        "        return [1.0]  # Single window case\n",
        "\n",
        "    sim_list = []\n",
        "    for i in range(len(embeddings) - 1):\n",
        "        sim = cosine_similarity([embeddings[i]], [embeddings[i+1]])[0][0]\n",
        "        sim_list.append(sim)\n",
        "    return sim_list\n",
        "\n",
        "def analyze_review_coherence(review_text):\n",
        "    # Handle missing or empty reviews\n",
        "    if pd.isna(review_text) or len(str(review_text).strip()) == 0:\n",
        "        return {\n",
        "            'num_windows': 0,\n",
        "            'coherence_scores': [],\n",
        "            'mean_coherence': np.nan,\n",
        "            'coherence_range': np.nan,\n",
        "            'word_count': 0\n",
        "        }\n",
        "\n",
        "    # -- Tokenize the review --\n",
        "    tokens = word_tokenize(str(review_text).lower())\n",
        "    word_count = len(tokens)\n",
        "\n",
        "    \"\"\"\n",
        "    # For very short reviews (less than window_size), return basic metrics\n",
        "    if word_count < window_size:\n",
        "        return {\n",
        "            'num_windows': 0,\n",
        "            'coherence_scores': [],\n",
        "            'mean_coherence': 1.0,  # Assume coherent if too short to analyze\n",
        "            'coherence_range': 0.0,\n",
        "            'word_count': word_count\n",
        "        }\n",
        "    \"\"\"\n",
        "\n",
        "    # -- Create sliding windows --\n",
        "    windows = create_sliding_windows(tokens, window_size, step)\n",
        "    num_windows = len(windows)\n",
        "\n",
        "    # -- Convert windows to text and get embeddings --\n",
        "    window_texts = [' '.join(window) for window in windows]\n",
        "    embeddings = model.encode(window_texts, convert_to_numpy=True)\n",
        "\n",
        "    # -- Coherence scores --\n",
        "    coherence_scores = compute_coherence_scores(embeddings)\n",
        "\n",
        "    # -- Metrics --\n",
        "    if coherence_scores:\n",
        "        median_coherence   = float(np.median(coherence_scores))\n",
        "        coherence_IQR  = float(np.percentile(coherence_scores, 75) - np.percentile(coherence_scores, 25)) # IQR\n",
        "    else:\n",
        "        mean_coherence   = 1.0\n",
        "        coherence_range  = 0.0\n",
        "\n",
        "    return {\n",
        "        'num_windows': num_windows,\n",
        "        'coherence_scores': coherence_scores,\n",
        "        'median_coherence': median_coherence,\n",
        "        'coherence_IQR': coherence_IQR,\n",
        "        'word_count': word_count\n",
        "    }"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-31T22:42:27.854884Z",
          "iopub.execute_input": "2025-07-31T22:42:27.855362Z",
          "iopub.status.idle": "2025-07-31T22:42:27.870086Z",
          "shell.execute_reply.started": "2025-07-31T22:42:27.855331Z",
          "shell.execute_reply": "2025-07-31T22:42:27.869051Z"
        },
        "id": "GqLGRld1RfsQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Sliding window parameters ---\n",
        "window_size = 7\n",
        "step = 4\n",
        "\n",
        "# --- Process all reviews ---\n",
        "print(\"Processing short reviews for coherence analysis...\")\n",
        "coherence_results = df_analysis['review'].apply(analyze_review_coherence)\n",
        "\n",
        "# --- Extract metrics into separate columns ---\n",
        "df_analysis['num_windows'] = coherence_results.apply(lambda x: x['num_windows'])\n",
        "df_analysis['median_coherence'] = coherence_results.apply(lambda x: x['median_coherence'])\n",
        "df_analysis['coherence_IQR'] = coherence_results.apply(lambda x: x['coherence_IQR'])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-31T23:01:45.074268Z",
          "iopub.execute_input": "2025-07-31T23:01:45.074656Z",
          "iopub.status.idle": "2025-07-31T23:02:50.511713Z",
          "shell.execute_reply.started": "2025-07-31T23:01:45.074627Z",
          "shell.execute_reply": "2025-07-31T23:02:50.510575Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "DY_TUt2fRfsQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Analysis summary ---\n",
        "print(\"\\nCoherence summary (human vs synthetic)\")\n",
        "print(\"--------------------------------------\")\n",
        "summary = df_analysis.groupby('source')[['median_coherence', 'coherence_IQR', 'num_windows']].describe()\n",
        "print(summary.round(3))\n",
        "\n",
        "# --- Mann-Whitney test ---\n",
        "from scipy.stats import mannwhitneyu\n",
        "h = df_analysis.loc[df_analysis['source']=='real',   'median_coherence']\n",
        "s = df_analysis.loc[df_analysis['source']=='synthetic','median_coherence']\n",
        "stat, p = mannwhitneyu(h, s, alternative='two-sided')\n",
        "print(f\"\\nMedian coherence difference (human vs synthetic)  U={stat:.1f}, p={p:.3f}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-31T23:03:38.294596Z",
          "iopub.execute_input": "2025-07-31T23:03:38.295071Z",
          "iopub.status.idle": "2025-07-31T23:03:38.336912Z",
          "shell.execute_reply.started": "2025-07-31T23:03:38.29504Z",
          "shell.execute_reply": "2025-07-31T23:03:38.335997Z"
        },
        "id": "stuERLn6RfsQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Key plots ---\n",
        "df_clean_for_plotting = df_analysis[df_analysis['median_coherence'].notna()].copy()\n",
        "\n",
        "plt.style.use('default')\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "colors = {'real': 'lightblue', 'synthetic': 'moccasin'}\n",
        "\n",
        "# -- Box plot --\n",
        "sns.boxplot(x='source', y='median_coherence', data=df_clean_for_plotting, ax=axes[0], palette=colors,linewidth=1)\n",
        "axes[0].set_title('Box Plots', loc='left', fontfamily='monospace')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# -- Violin plot --\n",
        "sns.violinplot(x='source', y='median_coherence', data=df_clean_for_plotting, ax=axes[1], palette=colors,linewidth=1)\n",
        "axes[1].set_title('Distribution Shapes', loc='left', fontfamily='monospace')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "# -- KDE plot --\n",
        "sns.kdeplot(data=df_clean_for_plotting, x='median_coherence', hue='source', common_norm=False, fill=True, ax=axes[2],linewidth=1)\n",
        "axes[2].set_title('Kernel Density Estimations', loc='left', fontfamily='monospace')\n",
        "axes[2].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "fig.axes[0].figure.savefig('sliding-window-coherence_boxplot.png')\n",
        "fig.axes[1].figure.savefig('sliding-window-coherence_violinplot.png')\n",
        "fig.axes[2].figure.savefig('sliding-window-coherence_kde.png')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-31T22:46:17.942404Z",
          "iopub.execute_input": "2025-07-31T22:46:17.942809Z",
          "iopub.status.idle": "2025-07-31T22:46:19.399519Z",
          "shell.execute_reply.started": "2025-07-31T22:46:17.942787Z",
          "shell.execute_reply": "2025-07-31T22:46:19.398478Z"
        },
        "id": "qczdkOZDRfsQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take-outs:\n",
        "Synthetic reviews exhibiting tighter local coherence scores. Neural system outputs score higher on narrow, window-based similarity metrics because they stay on one topic.\n",
        "\n"
      ],
      "metadata": {
        "id": "Nrf9dPeiRfsQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Save for later ---\n",
        "df_analysis.to_csv(\"df_analysis.csv\", index=False)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-31T23:03:49.764843Z",
          "iopub.execute_input": "2025-07-31T23:03:49.765908Z",
          "iopub.status.idle": "2025-07-31T23:03:49.788423Z",
          "shell.execute_reply.started": "2025-07-31T23:03:49.765872Z",
          "shell.execute_reply": "2025-07-31T23:03:49.787399Z"
        },
        "id": "IHhtkeAhRfsQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### POS tag enthropy"
      ],
      "metadata": {
        "id": "OhjUiy4DRfsQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Unigram* entropy used to measure grammatical *diversity*  \n",
        "*Bigram* entropy used to measure grammatical *predictability*\n",
        "\n",
        "Intuition:\n",
        "- no difference in unigram entropy between human and synthetic text\n",
        "- some difference in bi-gram entropy between synthetic text vs human text"
      ],
      "metadata": {
        "id": "QjsAn15VRfsQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Optional: re-load the data ---\n",
        "df_analysis = pd.read_csv(\"df_analysis.csv\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "bQziP0kZRfsQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q spacy\n",
        "!python -m spacy download en_core_web_sm\n",
        "\n",
        "import spacy, collections, math\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-31T22:46:50.275254Z",
          "iopub.execute_input": "2025-07-31T22:46:50.275657Z",
          "iopub.status.idle": "2025-07-31T22:47:13.590878Z",
          "shell.execute_reply.started": "2025-07-31T22:46:50.275629Z",
          "shell.execute_reply": "2025-07-31T22:47:13.589716Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "Bguc6PUIRfsR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Shannon entropy ---\n",
        "def pos_entropy(text: str) -> float:\n",
        "    \"\"\"Unigram POS entropy (bits/token).\"\"\"\n",
        "    doc = nlp(text)\n",
        "    counts = collections.Counter(token.pos_ for token in doc)\n",
        "    total  = sum(counts.values())\n",
        "    return -sum((c/total) * math.log2(c/total) for c in counts.values()) if total else 0.0\n",
        "\n",
        "# --- Conditional entropy ---\n",
        "def pos_bigram_entropy(text: str) -> float:\n",
        "    \"\"\"Bigram POS entropy H(Tₙ | Tₙ₋₁).  Returns bits.\"\"\"\n",
        "    doc = nlp(text)\n",
        "    tags = [tok.pos_ for tok in doc]\n",
        "    if len(tags) < 2:\n",
        "        return 0.0\n",
        "\n",
        "    bigram_counts = collections.Counter(zip(tags, tags[1:]))\n",
        "    prev_counts   = collections.Counter(tags[:-1])\n",
        "\n",
        "    H = 0.0\n",
        "    for (prev, curr), joint in bigram_counts.items():\n",
        "        p_joint = joint / (len(tags) - 1)\n",
        "        p_curr_given_prev = joint / prev_counts[prev]\n",
        "        H += p_joint * math.log2(p_curr_given_prev)\n",
        "    return -H"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-31T23:04:04.11472Z",
          "iopub.execute_input": "2025-07-31T23:04:04.115125Z",
          "iopub.status.idle": "2025-07-31T23:04:04.125107Z",
          "shell.execute_reply.started": "2025-07-31T23:04:04.115098Z",
          "shell.execute_reply": "2025-07-31T23:04:04.123574Z"
        },
        "id": "sWW7k65WRfsR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Run analysis ---\n",
        "df_analysis['pos_entropy'] = df_analysis['review'].astype(str).apply(pos_entropy)\n",
        "df_analysis['pos_bigram_entropy'] = df_analysis['review'].astype(str).apply(pos_bigram_entropy)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-31T23:04:06.500088Z",
          "iopub.execute_input": "2025-07-31T23:04:06.500478Z",
          "iopub.status.idle": "2025-07-31T23:04:34.044589Z",
          "shell.execute_reply.started": "2025-07-31T23:04:06.500453Z",
          "shell.execute_reply": "2025-07-31T23:04:34.043437Z"
        },
        "id": "I6kjW3RJRfsR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import mannwhitneyu\n",
        "\n",
        "real_uni  = df_analysis.loc[df_analysis['source']=='real',      'pos_entropy']\n",
        "synth_uni = df_analysis.loc[df_analysis['source']=='synthetic', 'pos_entropy']\n",
        "real_bi   = df_analysis.loc[df_analysis['source']=='real',      'pos_bigram_entropy']\n",
        "synth_bi  = df_analysis.loc[df_analysis['source']=='synthetic', 'pos_bigram_entropy']\n",
        "\n",
        "# --- Descriptive stats ---\n",
        "print(\"Unigram entropy\")\n",
        "print(f\"  Real      : n={len(real_uni):3d}, mean={real_uni.mean():.3f}, sd={real_uni.std():.3f}\")\n",
        "print(f\"  Synthetic : n={len(synth_uni):3d}, mean={synth_uni.mean():.3f}, sd={synth_uni.std():.3f}\")\n",
        "\n",
        "print(\"Bigram entropy\")\n",
        "print(f\"  Real      : n={len(real_bi):3d}, mean={real_bi.mean():.3f}, sd={real_bi.std():.3f}\")\n",
        "print(f\"  Synthetic : n={len(synth_bi):3d}, mean={synth_bi.mean():.3f}, sd={synth_bi.std():.3f}\")\n",
        "\n",
        "# --- Two-sided Mann–Whitney ---\n",
        "u_uni, p_uni = mannwhitneyu(real_uni, synth_uni, alternative='two-sided')\n",
        "u_bi,  p_bi  = mannwhitneyu(real_bi,  synth_bi,  alternative='two-sided')\n",
        "\n",
        "print(\"\\nTests\")\n",
        "print(f\"Unigram entropy: p={p_uni:.3g}\")\n",
        "print(f\"Bigram entropy : p={p_bi:.3g}\")\n",
        "\n",
        "def rank_biserial(u_stat, n1, n2):\n",
        "    r = 1 - (2 * u_stat) / (n1 * n2)\n",
        "    return r\n",
        "\n",
        "# --- Rank bi-serial correlation (effect sizes) ---\n",
        "r_uni = rank_biserial(u_uni, len(real_uni), len(synth_uni))\n",
        "r_bi  = rank_biserial(u_bi,  len(real_bi),  len(synth_bi))\n",
        "print(\"\\nEffect sizes\")\n",
        "print(f\"Rank Biserial (Unigram): {r_uni:.3f}\")\n",
        "print(f\"Rank Biserial (Bigram) : {r_bi:.3f}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-31T23:05:06.569371Z",
          "iopub.execute_input": "2025-07-31T23:05:06.569786Z",
          "iopub.status.idle": "2025-07-31T23:05:06.591466Z",
          "shell.execute_reply.started": "2025-07-31T23:05:06.569759Z",
          "shell.execute_reply": "2025-07-31T23:05:06.590514Z"
        },
        "id": "dobOeAmQRfsR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Key charts ---\n",
        "plt.style.use('default')\n",
        "fig, axes = plt.subplots(1, 2, figsize=(18, 4))\n",
        "colors = {'real': 'steelblue', 'synthetic': 'orange'}\n",
        "\n",
        "sns.histplot(data=df_analysis, x='pos_entropy', hue='source', kde=True, bins=20, ax=axes[0], palette=colors,linewidth=0.5)\n",
        "axes[0].set_title('Unigram POS Entropy Distribution', loc='left', fontfamily='monospace')\n",
        "\n",
        "sns.histplot(data=df_analysis, x='pos_bigram_entropy', hue='source', kde=True, bins=20, ax=axes[1], palette=colors,linewidth=0.5)\n",
        "axes[1].set_title('Bigram POS Entropy Distribution', loc='left', fontfamily='monospace')\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "fig.axes[0].figure.savefig('unigram_entropy.png')\n",
        "fig.axes[1].figure.savefig('bigram_entropy.png')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-31T22:49:56.660018Z",
          "iopub.execute_input": "2025-07-31T22:49:56.660444Z",
          "iopub.status.idle": "2025-07-31T22:49:58.011444Z",
          "shell.execute_reply.started": "2025-07-31T22:49:56.660414Z",
          "shell.execute_reply": "2025-07-31T22:49:58.010213Z"
        },
        "id": "psweZE2TRfsR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Save for later\n",
        "df_analysis.to_csv(\"df_analysis.csv\", index=False)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-31T23:05:12.290467Z",
          "iopub.execute_input": "2025-07-31T23:05:12.290869Z",
          "iopub.status.idle": "2025-07-31T23:05:12.319354Z",
          "shell.execute_reply.started": "2025-07-31T23:05:12.29084Z",
          "shell.execute_reply": "2025-07-31T23:05:12.31805Z"
        },
        "id": "vWVpXbTKRfsR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Predictive model"
      ],
      "metadata": {
        "id": "Q5byH6GIRfsR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_predict, cross_val_score\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix, ConfusionMatrixDisplay, roc_auc_score, roc_curve\n",
        "from sklearn.calibration import CalibratedClassifierCV, calibration_curve"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-01T08:38:46.814209Z",
          "iopub.execute_input": "2025-08-01T08:38:46.814491Z",
          "iopub.status.idle": "2025-08-01T08:38:46.989577Z",
          "shell.execute_reply.started": "2025-08-01T08:38:46.814472Z",
          "shell.execute_reply": "2025-08-01T08:38:46.988874Z"
        },
        "id": "A1dBM7wrRfsU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Optional: re-load train data ---\n",
        "df_analysis = pd.read_csv(\"df_analysis.csv\")\n",
        "df_analysis.info()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-01T08:23:36.077451Z",
          "iopub.execute_input": "2025-08-01T08:23:36.078018Z",
          "iopub.status.idle": "2025-08-01T08:23:36.120055Z",
          "shell.execute_reply.started": "2025-08-01T08:23:36.07799Z",
          "shell.execute_reply": "2025-08-01T08:23:36.119257Z"
        },
        "id": "l86kma6hRfsV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Data preparation ---\n",
        "X = df_analysis[['median_coherence',\n",
        "                 'coherence_IQR',\n",
        "                 'pos_entropy',\n",
        "                 'pos_bigram_entropy']]\n",
        "y = (df_analysis['source'] == 'synthetic').astype(int)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-01T08:45:29.181106Z",
          "iopub.execute_input": "2025-08-01T08:45:29.181463Z",
          "iopub.status.idle": "2025-08-01T08:45:29.188451Z",
          "shell.execute_reply.started": "2025-08-01T08:45:29.181439Z",
          "shell.execute_reply": "2025-08-01T08:45:29.1874Z"
        },
        "id": "OZJazsJ8RfsV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic regression"
      ],
      "metadata": {
        "id": "1vWgEzAGRfsV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Logistic regression setup ---\n",
        "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "clf_log = Pipeline([\n",
        "    ('scale', StandardScaler()),\n",
        "    ('logit', LogisticRegression(max_iter=5000))\n",
        "])\n",
        "\n",
        "y_pred_log = cross_val_predict(clf_log, X, y, cv=cv, method='predict')\n",
        "print(classification_report(y, y_pred_log, target_names=['real', 'synthetic']))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-01T08:52:12.790143Z",
          "iopub.execute_input": "2025-08-01T08:52:12.790454Z",
          "iopub.status.idle": "2025-08-01T08:52:13.358791Z",
          "shell.execute_reply.started": "2025-08-01T08:52:12.790432Z",
          "shell.execute_reply": "2025-08-01T08:52:13.358052Z"
        },
        "id": "8HIq3TW0RfsV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Log misclassification examples ---\n",
        "df_analysis['pred_source_log'] = np.where(y_pred_log == 1, 'synthetic', 'real')\n",
        "false_synthetic = df_analysis[(df_analysis['source'] == 'real') & (df_analysis['pred_source_log'] == 'synthetic')].head(5)\n",
        "false_real = df_analysis[(df_analysis['source'] == 'synthetic') & (df_analysis['pred_source_log'] == 'real')].head(5)\n",
        "\n",
        "print(\"Real → predicted synthetic\")\n",
        "for idx, row in false_synthetic.iterrows():\n",
        "    print(f\"Idx {idx}: {row['review'][:200]}…\")\n",
        "\n",
        "print(\"\\nSynthetic → predicted real\")\n",
        "for idx, row in false_real.iterrows():\n",
        "    print(f\"Idx {idx}: {row['review'][:200]}…\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-31T23:09:48.59722Z",
          "iopub.execute_input": "2025-07-31T23:09:48.597617Z",
          "iopub.status.idle": "2025-07-31T23:09:48.614856Z",
          "shell.execute_reply.started": "2025-07-31T23:09:48.597591Z",
          "shell.execute_reply": "2025-07-31T23:09:48.613785Z"
        },
        "id": "NwWSxEF4RfsV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "err_bin = df_analysis[df_analysis['source'] != df_analysis['pred_source_log']]\n",
        "avg = err_bin.groupby(['word_count_bin_str', 'pred_source_log']).size().unstack(fill_value=0)\n",
        "print(avg)\n",
        "\n",
        "# real → the review was synthetic but the model called it real (false-real errors).\n",
        "# synthetic → the review was real but the model called it synthetic (false-synthetic errors)."
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-01T21:57:08.631558Z",
          "iopub.execute_input": "2025-08-01T21:57:08.633051Z",
          "iopub.status.idle": "2025-08-01T21:57:08.686547Z",
          "shell.execute_reply.started": "2025-08-01T21:57:08.633005Z",
          "shell.execute_reply": "2025-08-01T21:57:08.685349Z"
        },
        "id": "y_fmKlsBRfsV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "err_rating = df_analysis[df_analysis['source'] != df_analysis['pred_source_log']]\n",
        "avg = err_rating.groupby(['rating', 'pred_source_log']).size().unstack(fill_value=0)\n",
        "print(avg)\n",
        "\n",
        "# real → the review was synthetic but the model called it real (false-real errors).\n",
        "# synthetic → the review was real but the model called it synthetic (false-synthetic errors)."
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-01T21:58:42.246358Z",
          "iopub.execute_input": "2025-08-01T21:58:42.246712Z",
          "iopub.status.idle": "2025-08-01T21:58:42.26206Z",
          "shell.execute_reply.started": "2025-08-01T21:58:42.246684Z",
          "shell.execute_reply": "2025-08-01T21:58:42.260664Z"
        },
        "id": "5rGaxjT-RfsV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Confusion matrix ---\n",
        "cm_log = confusion_matrix(y, y_pred_log, labels=[0, 1])\n",
        "disp = ConfusionMatrixDisplay(cm_log, display_labels=['real', 'synthetic'])\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(4, 4))\n",
        "disp.plot(ax=ax, cmap='Blues', colorbar=False)\n",
        "\n",
        "ax.set_title(\"Confusion Matrix\", fontfamily='monospace', fontsize=10)\n",
        "ax.set_xlabel(\"Predicted Label\", fontfamily='monospace', fontsize=10)\n",
        "ax.set_ylabel(\"True Label\", fontfamily='monospace', fontsize=10)\n",
        "\n",
        "ax.tick_params(labelsize=8)\n",
        "for label in ax.get_xticklabels() + ax.get_yticklabels():\n",
        "    label.set_fontfamily('monospace')\n",
        "\n",
        "plt.savefig('confusion_matrix_log.png', dpi=300, bbox_inches='tight')\n",
        "plt.title(\"Confusion matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-01T08:54:33.64689Z",
          "iopub.execute_input": "2025-08-01T08:54:33.64724Z",
          "iopub.status.idle": "2025-08-01T08:54:34.023904Z",
          "shell.execute_reply.started": "2025-08-01T08:54:33.647219Z",
          "shell.execute_reply": "2025-08-01T08:54:34.022987Z"
        },
        "id": "3m3cYt8VRfsV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- ROC curve / AUC ---\n",
        "y_prob_log = cross_val_predict(clf_log, X, y, cv=cv, method='predict_proba')[:, 1]\n",
        "fpr, tpr, _ = roc_curve(y, y_prob_log)\n",
        "auc = roc_auc_score(y, y_prob_log)\n",
        "\n",
        "print(f\"ROC AUC = {auc:.3f}\")\n",
        "\n",
        "plt.plot(fpr, tpr, label=f\"AUC = {auc:.3f}\")\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlabel(\"False Positive Rate\", fontfamily='monospace', fontsize=10)\n",
        "plt.ylabel(\"True Positive Rate\", fontfamily='monospace', fontsize=10)\n",
        "plt.title(\"ROC curve\", fontfamily='monospace', fontsize=12, loc='left')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-31T23:15:20.060855Z",
          "iopub.execute_input": "2025-07-31T23:15:20.061884Z",
          "iopub.status.idle": "2025-07-31T23:15:20.646526Z",
          "shell.execute_reply.started": "2025-07-31T23:15:20.061851Z",
          "shell.execute_reply": "2025-07-31T23:15:20.645498Z"
        },
        "id": "-iNgG-vXRfsV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression - Recursive Feature Elimination with Cross-Validation"
      ],
      "metadata": {
        "id": "8r2MfqwiRfsW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Logistic regression with RFECV setup ---\n",
        "clf_log_cv = Pipeline([\n",
        "    ('scale', StandardScaler()),\n",
        "    ('clf', LogisticRegressionCV(cv=10, penalty='l2', solver='liblinear'))\n",
        "])\n",
        "selector = RFECV(clf_log_cv, cv=5, scoring='accuracy',importance_getter='named_steps.clf.coef_')\n",
        "selector.fit(X, y)\n",
        "print(\"Optimal number of features:\", selector.n_features_)\n",
        "print(\"Ranking:\", selector.ranking_)\n",
        "print(\"Selected indices:\", selector.support_)\n",
        "\n",
        "X_reduced = X.iloc[:, selector.support_]\n",
        "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "clf_log_optimal = Pipeline([\n",
        "    ('scale', StandardScaler()),\n",
        "    ('logit', LogisticRegression(max_iter=5000))\n",
        "])\n",
        "\n",
        "# --- Get predictions and F1 scores for each fold ---\n",
        "y_pred_log_optimal = cross_val_predict(clf_log_optimal, X_reduced, y, cv=cv, method='predict')\n",
        "cv_f1_scores = cross_val_score(clf_log_optimal, X_reduced, y, cv=cv,\n",
        "                               scoring='f1', # automatically uses pos_label='1' which maps to 'synthetic'\n",
        "                               )\n",
        "\n",
        "print(classification_report(y, y_pred_log_optimal, target_names=['real', 'synthetic']))\n",
        "\n",
        "# --- Feature coefficients ---\n",
        "clf_log_optimal.fit(X_reduced, y)\n",
        "coefficients = clf_log_optimal.named_steps['logit'].coef_[0]\n",
        "feature_names = X_reduced.columns\n",
        "\n",
        "print(\"\\n=== Feature Coefficients ===\")\n",
        "for name, coef in zip(feature_names, coefficients):\n",
        "    direction = \"increases\" if coef > 0 else \"decreases\"\n",
        "    print(f\"{name}: {coef:.3f} ({direction} synthetic probability)\")\n",
        "\n",
        "# --- Cross-Validation Stability ---\n",
        "print(f\"\\n=== Cross-Validation Stability ===\")\n",
        "print(f\"F1-scores across folds: {[f'{score:.3f}' for score in cv_f1_scores]}\")\n",
        "print(f\"Mean F1: {cv_f1_scores.mean():.3f} ± {cv_f1_scores.std():.3f}\")\n",
        "print(f\"Range: {cv_f1_scores.min():.3f} - {cv_f1_scores.max():.3f}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-01T20:58:30.938341Z",
          "iopub.execute_input": "2025-08-01T20:58:30.938649Z",
          "iopub.status.idle": "2025-08-01T20:58:34.774735Z",
          "shell.execute_reply.started": "2025-08-01T20:58:30.938628Z",
          "shell.execute_reply": "2025-08-01T20:58:34.774027Z"
        },
        "id": "AzqIsawWRfsW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Confusion matrix ---\n",
        "cm_log_optimal = confusion_matrix(y, y_pred_log, labels=[0, 1])\n",
        "disp = ConfusionMatrixDisplay(cm_log_optimal, display_labels=['real', 'synthetic'])\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(4, 4))\n",
        "disp.plot(ax=ax, cmap='Blues', colorbar=False)\n",
        "\n",
        "ax.set_title(\"Confusion Matrix\", fontfamily='monospace', fontsize=10)\n",
        "ax.set_xlabel(\"Predicted Label\", fontfamily='monospace', fontsize=10)\n",
        "ax.set_ylabel(\"True Label\", fontfamily='monospace', fontsize=10)\n",
        "\n",
        "ax.tick_params(labelsize=8)\n",
        "for label in ax.get_xticklabels() + ax.get_yticklabels():\n",
        "    label.set_fontfamily('monospace')\n",
        "\n",
        "plt.savefig('confusion_matrix_log_optimal.png', dpi=300, bbox_inches='tight')\n",
        "plt.title(\"Confusion matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-01T21:01:25.901984Z",
          "iopub.execute_input": "2025-08-01T21:01:25.903414Z",
          "iopub.status.idle": "2025-08-01T21:01:26.481134Z",
          "shell.execute_reply.started": "2025-08-01T21:01:25.903362Z",
          "shell.execute_reply": "2025-08-01T21:01:26.479988Z"
        },
        "id": "BwkwdKi3RfsW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Support Vector Classifier"
      ],
      "metadata": {
        "id": "4TssNWQnRfsW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Support Vector Classifier setup ---\n",
        "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "clf_svc = Pipeline([\n",
        "    ('scale', StandardScaler()),\n",
        "    ('svm',  SVC(kernel='rbf', C=1.0, probability=True, random_state=42))\n",
        "])\n",
        "\n",
        "y_pred_svc = cross_val_predict(clf_svc, X, y, cv=cv, method='predict')\n",
        "print(classification_report(y, y_pred_svc, target_names=['real', 'synthetic']))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-31T23:15:31.647562Z",
          "iopub.execute_input": "2025-07-31T23:15:31.64809Z",
          "iopub.status.idle": "2025-07-31T23:15:32.629063Z",
          "shell.execute_reply.started": "2025-07-31T23:15:31.648056Z",
          "shell.execute_reply": "2025-07-31T23:15:32.628024Z"
        },
        "id": "xHy_QPvjRfsW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- SVC misclassification examples ---\n",
        "df_analysis['pred_source_svc'] = np.where(y_pred_svc == 1, 'synthetic', 'real')\n",
        "false_synthetic = df_analysis[(df_analysis['source'] == 'real') & (df_analysis['pred_source_svc'] == 'synthetic')].head(5)\n",
        "false_real = df_analysis[(df_analysis['source'] == 'synthetic') & (df_analysis['pred_source_svc'] == 'real')].head(5)\n",
        "\n",
        "print(\"Real → predicted synthetic\")\n",
        "for idx, row in false_synthetic.iterrows():\n",
        "    print(f\"Idx {idx}: {row['review'][:200]}…\")\n",
        "\n",
        "print(\"\\nSynthetic → predicted real\")\n",
        "for idx, row in false_real.iterrows():\n",
        "    print(f\"Idx {idx}: {row['review'][:200]}…\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-31T23:15:36.100752Z",
          "iopub.execute_input": "2025-07-31T23:15:36.101179Z",
          "iopub.status.idle": "2025-07-31T23:15:36.117826Z",
          "shell.execute_reply.started": "2025-07-31T23:15:36.10115Z",
          "shell.execute_reply": "2025-07-31T23:15:36.116457Z"
        },
        "id": "GHWog36URfsW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Misclassifications by bucket ---\n",
        "err = df_analysis[df_analysis['source'] != df_analysis['pred_source_svc']]\n",
        "avg = err.groupby(['word_count_bin_str', 'pred_source_svc']).size().unstack(fill_value=0)\n",
        "print(avg)\n",
        "\n",
        "# real → the review was synthetic but the model called it real (false-real errors).\n",
        "# synthetic → the review was real but the model called it synthetic (false-synthetic errors)."
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-31T23:16:13.897286Z",
          "iopub.execute_input": "2025-07-31T23:16:13.8977Z",
          "iopub.status.idle": "2025-07-31T23:16:13.912108Z",
          "shell.execute_reply.started": "2025-07-31T23:16:13.897671Z",
          "shell.execute_reply": "2025-07-31T23:16:13.911115Z"
        },
        "id": "q9GNyoJFRfsW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Confusion matrix ---\n",
        "cm_svc = confusion_matrix(y, y_pred_svc, labels=[0, 1])\n",
        "disp = ConfusionMatrixDisplay(cm_svc, display_labels=['real', 'synthetic'])\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(4, 4))\n",
        "disp.plot(ax=ax, cmap='Blues', colorbar=False)\n",
        "\n",
        "ax.set_title(\"Confusion Matrix\", fontfamily='monospace', fontsize=10)\n",
        "ax.set_xlabel(\"Predicted Label\", fontfamily='monospace', fontsize=10)\n",
        "ax.set_ylabel(\"True Label\", fontfamily='monospace', fontsize=10)\n",
        "\n",
        "ax.tick_params(labelsize=8)\n",
        "for label in ax.get_xticklabels() + ax.get_yticklabels():\n",
        "    label.set_fontfamily('monospace')\n",
        "\n",
        "plt.savefig('confusion_matrix_svc.png', dpi=300, bbox_inches='tight')\n",
        "\n",
        "plt.title(\"Confusion matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-31T23:18:38.440923Z",
          "iopub.execute_input": "2025-07-31T23:18:38.442579Z",
          "iopub.status.idle": "2025-07-31T23:18:38.849194Z",
          "shell.execute_reply.started": "2025-07-31T23:18:38.442527Z",
          "shell.execute_reply": "2025-07-31T23:18:38.848048Z"
        },
        "id": "C4MFYdk3RfsW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Train final model ---\n",
        "clf_svc.fit(X, y)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-31T23:26:45.055863Z",
          "iopub.execute_input": "2025-07-31T23:26:45.056298Z",
          "iopub.status.idle": "2025-07-31T23:26:45.280951Z",
          "shell.execute_reply.started": "2025-07-31T23:26:45.056271Z",
          "shell.execute_reply": "2025-07-31T23:26:45.280007Z"
        },
        "id": "vx9MMPjBRfsW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Out of sample prediction"
      ],
      "metadata": {
        "id": "Z7fllJ_YRfsX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Optional: re-load test data ---\n",
        "df_analysis_test = pd.read_csv(\"df_analysis_test.csv\")\n",
        "df_analysis_test.info()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-01T21:11:19.026603Z",
          "iopub.execute_input": "2025-08-01T21:11:19.026997Z",
          "iopub.status.idle": "2025-08-01T21:11:19.046131Z",
          "shell.execute_reply.started": "2025-08-01T21:11:19.026972Z",
          "shell.execute_reply": "2025-08-01T21:11:19.044853Z"
        },
        "id": "PvEMX_HbRfsX"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Create a working copy of test dataset ---\n",
        "df_analysis_test = df_test.copy()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-01T21:05:13.829544Z",
          "iopub.execute_input": "2025-08-01T21:05:13.830617Z",
          "iopub.status.idle": "2025-08-01T21:05:13.849333Z",
          "shell.execute_reply.started": "2025-08-01T21:05:13.830574Z",
          "shell.execute_reply": "2025-08-01T21:05:13.847347Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "YIZFcrv1RfsX"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Running this cell requires running cells from Analysis section to activate helper functions\n",
        "\n",
        "# --- Run sliding-window coherence analysis ---\n",
        "coherence_results = df_analysis_test['review'].apply(analyze_review_coherence)\n",
        "df_analysis_test['num_windows'] = coherence_results.apply(lambda x: x['num_windows'])\n",
        "df_analysis_test['median_coherence'] = coherence_results.apply(lambda x: x['median_coherence'])\n",
        "df_analysis_test['coherence_IQR'] = coherence_results.apply(lambda x: x['coherence_IQR'])\n",
        "\n",
        "# --- Run unigram and bigram entropy analysis ---\n",
        "df_analysis_test['pos_entropy'] = df_analysis_test['review'].astype(str).apply(pos_entropy)\n",
        "df_analysis_test['pos_bigram_entropy'] = df_analysis_test['review'].astype(str).apply(pos_bigram_entropy)\n",
        "\n",
        "# --- Save for later ---\n",
        "df_analysis_test.to_csv(\"df_analysis_test.csv\", index=False)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-31T23:34:05.93705Z",
          "iopub.execute_input": "2025-07-31T23:34:05.938114Z",
          "iopub.status.idle": "2025-07-31T23:34:44.81696Z",
          "shell.execute_reply.started": "2025-07-31T23:34:05.938069Z",
          "shell.execute_reply": "2025-07-31T23:34:44.816021Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "lgTotbPvRfsX"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- OPTION 1: Full test set, no downsampling of synthetic records ---\n",
        "X_test_reduced = df_adjusted_test[['pos_entropy', 'pos_bigram_entropy']] # X_test_reduced refers to reduced set of features\n",
        "y_test = (df_analysis_test['source'] == 'synthetic').astype(int)\n",
        "print(\"X shape\", X_test.shape)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-31T23:49:36.041542Z",
          "iopub.execute_input": "2025-07-31T23:49:36.041984Z",
          "iopub.status.idle": "2025-07-31T23:49:36.051823Z",
          "shell.execute_reply.started": "2025-07-31T23:49:36.041957Z",
          "shell.execute_reply": "2025-07-31T23:49:36.050533Z"
        },
        "id": "-DQdOIpLRfsX"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- OPTION 2: Realistic test set, with downsampling of synthetic records ---\n",
        "real_rows  = df_analysis_test[df_analysis_test['source'] == 'real']\n",
        "synth_rows = df_analysis_test[df_analysis_test['source'] == 'synthetic']\n",
        "synth_sub = synth_rows.sample(n=100, random_state=42)\n",
        "df_adjusted_test = pd.concat([real_rows, synth_sub], ignore_index=True)\n",
        "\n",
        "X_test_reduced = df_adjusted_test[['pos_entropy', 'pos_bigram_entropy']] # X_test_reduced refers to reduced set of features\n",
        "y_test = (df_adjusted_test['source'] == 'synthetic').astype(int)\n",
        "\n",
        "print(\"X shape (4 features)\", X_test.shape)\n",
        "print(\"X shape (2 features)\", X_test_reduced.shape)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-01T21:32:22.440131Z",
          "iopub.execute_input": "2025-08-01T21:32:22.440586Z",
          "iopub.status.idle": "2025-08-01T21:32:22.457983Z",
          "shell.execute_reply.started": "2025-08-01T21:32:22.440555Z",
          "shell.execute_reply": "2025-08-01T21:32:22.456655Z"
        },
        "id": "2U-nsjSaRfsX"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Predict with optimal Log model ---\n",
        "log_pred = clf_log_optimal.predict(X_test_reduced)\n",
        "log_report = classification_report(y_test, log_pred, target_names=['real','synthetic'])\n",
        "\n",
        "# --- Evaluate ---\n",
        "\n",
        "print(\"Logistic Regression\")\n",
        "print(log_report)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, log_pred))\n",
        "\n",
        "with open('model_evaluation_log_optimal.txt', 'w') as f:\n",
        "    f.write(\"Logistic Regression\\n\")\n",
        "    f.write(log_report + \"\\n\")\n",
        "    f.write(f\"Accuracy: {accuracy_score(y_test, log_pred)}\\n\\n\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-01T21:12:18.795711Z",
          "iopub.execute_input": "2025-08-01T21:12:18.796125Z",
          "iopub.status.idle": "2025-08-01T21:12:18.816225Z",
          "shell.execute_reply.started": "2025-08-01T21:12:18.796097Z",
          "shell.execute_reply": "2025-08-01T21:12:18.814937Z"
        },
        "id": "w9vl7808RfsX"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Threshold analysis on out-of-sample data ---\n",
        "y_proba_test = clf_log_optimal.predict_proba(X_test_reduced)[:, 1]  # Probability of synthetic (class 1)\n",
        "\n",
        "print(\"\\n=== Threshold Analysis (Out-of-Sample) ===\")\n",
        "for threshold in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
        "    y_pred_thresh = (y_proba_test >= threshold).astype(int)\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred_thresh, labels=[0, 1])\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    detection_rate = tp / (tp + fn)  # Recall for synthetic\n",
        "    false_positive_rate = fp / (fp + tn)  # FPR for real\n",
        "\n",
        "    print(f\"Threshold {threshold}: Detection={detection_rate:.1%}, FPR={false_positive_rate:.1%}\")\n",
        "\n",
        "# --- Confusion matrix for default 0.5 threshold ---\n",
        "print(\"\\n=== Confusion Matrix (Out-of-Sample) ===\")\n",
        "cm = confusion_matrix(y_test, log_pred, labels=[0, 1])\n",
        "cm_df = pd.DataFrame(cm,\n",
        "                     index=['Actual Real (0)', 'Actual Synthetic (1)'],\n",
        "                     columns=['Predicted Real (0)', 'Predicted Synthetic (1)'])\n",
        "print(cm_df)\n",
        "\n",
        "# --- Interpretation ---\n",
        "print(f\"\\n=== Concrete Results ===\")\n",
        "print(f\"Of {sum(y_test == 0)} human reviews: {cm[0,0]} correctly identified, {cm[0,1]} flagged as bots\")\n",
        "print(f\"Of {sum(y_test == 1)} synthetic reviews: {cm[1,1]} caught, {cm[1,0]} slipped through\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-01T21:18:09.999022Z",
          "iopub.execute_input": "2025-08-01T21:18:09.999432Z",
          "iopub.status.idle": "2025-08-01T21:18:10.031778Z",
          "shell.execute_reply.started": "2025-08-01T21:18:09.999405Z",
          "shell.execute_reply": "2025-08-01T21:18:10.03042Z"
        },
        "id": "X8rCMMScRfsX"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Confusion matrix ---\n",
        "cm_test = confusion_matrix(y_test, log_pred, labels=[0, 1])\n",
        "disp = ConfusionMatrixDisplay(cm_test, display_labels=['real', 'synthetic'])\n",
        "fig, ax = plt.subplots(figsize=(4, 4))\n",
        "disp.plot(ax=ax, cmap='Blues', colorbar=False)\n",
        "ax.set_title(\"Out-of-Sample Confusion Matrix\", fontfamily='monospace', fontsize=10)\n",
        "ax.set_xlabel(\"Predicted Label\", fontfamily='monospace', fontsize=10)\n",
        "ax.set_ylabel(\"True Label\", fontfamily='monospace', fontsize=10)\n",
        "ax.tick_params(labelsize=8)\n",
        "for label in ax.get_xticklabels() + ax.get_yticklabels():\n",
        "    label.set_fontfamily('monospace')\n",
        "\n",
        "# Clear the default text annotations first\n",
        "for text in ax.texts:\n",
        "    text.set_visible(False)\n",
        "\n",
        "# Add custom annotations with appropriate colors for visibility\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        count = cm_test[i, j]\n",
        "        total = cm_test[i].sum()\n",
        "        percentage = count / total * 100\n",
        "\n",
        "        # Use white text on dark cells, black text on light cells\n",
        "        text_color = 'white' if cm_test[i, j] > cm_test.max() / 2 else 'black'\n",
        "\n",
        "        ax.text(j, i, f'{count}\\n({percentage:.1f}%)',\n",
        "                ha='center', va='center', fontsize=9, fontfamily='monospace',\n",
        "                color=text_color, weight='bold')\n",
        "\n",
        "plt.savefig('confusion_matrix_out_of_sample.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-01T21:28:07.517226Z",
          "iopub.execute_input": "2025-08-01T21:28:07.517563Z",
          "iopub.status.idle": "2025-08-01T21:28:07.919472Z",
          "shell.execute_reply.started": "2025-08-01T21:28:07.517539Z",
          "shell.execute_reply": "2025-08-01T21:28:07.9183Z"
        },
        "id": "jT7U7BQzRfsX"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sHBjghE9QHeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# My result: Out of sample prediction finished successfully"
      ],
      "metadata": {
        "id": "TpZb1N6CQGA0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}